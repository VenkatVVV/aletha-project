{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de5120bc-c30f-4434-8a29-2ba7ac01ce39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json \n",
    "import logging \n",
    "import asyncio\n",
    "import requests \n",
    "LLM_API_SECRET_SCOPE = \"RAG_GEMINI_LLM\"\n",
    "LLM_API_SECRET_KEY = \"INSERT_GEMINI_API_KEY\"\n",
    "FRAUD_DETECTION_NOTEBOOK_PATH = \"aletha-project/fraudDetectionModel\"\n",
    "CREDIT_RISK_NOTEBOOK_PATH = \"aletha-project/creditRiskScoreModel\"\n",
    "CUSTOMER_SEGMENTATION_NOTEBOOK_PATH = \"aletha-project/customerSegmentationModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d60bd2-2907-42f3-8f18-2d9da588b199",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46ff0048-a44d-4a6b-8198-0661f549d722",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.secrets.put(scope=LLM_API_SECRET_SCOPE, key=LLM_API_SECRET_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed60f0ab-f77a-44f2-a699-951aee026f15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Try to get the current user for logging and auditing\n",
    "try:\n",
    "    current_user = dbutils.notebook.getContext().tags().get(\"user\").get()\n",
    "except Exception:\n",
    "    current_user = \"unknown_user\"\n",
    "logger.info(f\"RAG Router initialized by user: {current_user}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9826030c-92f9-419a-9119-50570bc383ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def classify_query(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies the user query to determine which notebook to run or if it's a general inquiry.\n",
    "\n",
    "    Args:\n",
    "        query (str): The user's input query.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the relevant notebook, or \"LLM\" for a general inquiry.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    # Define keywords for each domain\n",
    "    if re.search(r'\\b(fraud|detect fraud|fraud detection|fraudulent transaction)\\b', query_lower):\n",
    "        logger.info(f\"Query '{query}' classified as: Fraud Detection\")\n",
    "        return FRAUD_DETECTION_NOTEBOOK_PATH\n",
    "    elif re.search(r'\\b(credit risk|loan risk|risk score|credit score model)\\b', query_lower):\n",
    "        logger.info(f\"Query '{query}' classified as: Credit Risk\")\n",
    "        return CREDIT_RISK_NOTEBOOK_PATH\n",
    "    elif re.search(r'\\b(customer segmentation|customer categories|customer groups|segment customers|bucket customers)\\b', query_lower):\n",
    "        logger.info(f\"Query '{query}' classified as: Customer Segmentation\")\n",
    "        return CUSTOMER_SEGMENTATION_NOTEBOOK_PATH\n",
    "    else:\n",
    "        logger.info(f\"Query '{query}' classified as: General Inquiry (LLM)\")\n",
    "        return \"LLM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fd999fd9-e73f-4d4c-9022-a1be485d9a05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "async def call_llm(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls the Gemini API to get a response for a general inquiry.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the LLM.\n",
    "\n",
    "    Returns:\n",
    "        str: The LLM's generated text response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve API key securely from Databricks Secrets\n",
    "        api_key = dbutils.secrets.get(scope=LLM_API_SECRET_SCOPE, key=LLM_API_SECRET_KEY)\n",
    "        logger.info(\"Successfully retrieved LLM API key from Databricks Secrets.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to retrieve LLM API key from secrets: {e}. Please ensure scope '{LLM_API_SECRET_SCOPE}' and key '{LLM_API_SECRET_KEY}' exist and are accessible.\")\n",
    "        return \"Error: LLM API key could not be retrieved securely.\"\n",
    "\n",
    "    chat_history = []\n",
    "    chat_history.append({ \"role\": \"user\", \"parts\": [{ \"text\": prompt }] })\n",
    "    payload = { \"contents\": chat_history }\n",
    "    api_url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.post(api_url, headers={'Content-Type': 'application/json'}, json=payload)\n",
    "        response.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
    "        result = response.json()\n",
    "\n",
    "        if result.get(\"candidates\") and len(result[\"candidates\"]) > 0 and \\\n",
    "           result[\"candidates\"][0].get(\"content\") and result[\"candidates\"][0][\"content\"].get(\"parts\") and \\\n",
    "           len(result[\"candidates\"][0][\"content\"][\"parts\"]) > 0:\n",
    "            llm_response_text = result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "            logger.info(\"LLM call successful.\")\n",
    "            return llm_response_text\n",
    "        else:\n",
    "            logger.warning(f\"LLM did not return a valid response structure. Response: {result}\")\n",
    "            return \"LLM did not return a valid response.\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Error calling LLM API: {e}. Request URL: {api_url}\")\n",
    "        return f\"Error calling LLM API: {e}\"\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"Error decoding LLM response: {e}. Raw response: {response.text}\")\n",
    "        return f\"Error decoding LLM response: {e}. (Check raw response in logs)\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An unexpected error occurred during LLM call: {e}\")\n",
    "        return f\"An unexpected error occurred with LLM call: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9bfc3666-0f48-4fd3-9c86-5b3d492ec44d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Enter query below and RAG will route it to the appropriate ML model or answer generally.\")\n",
    "print(\"Examples: 'Run fraud detection model', 'Tell me about credit risk', 'Segment my customers', 'What is Databricks?'\")\n",
    "\n",
    "# Get user input\n",
    "user_query = input(\"Your query: \")\n",
    "\n",
    "logger.info(f\"Processing query: '{user_query}'\")\n",
    "\n",
    "# Classify the query\n",
    "target_action = classify_query(user_query)\n",
    "\n",
    "print(f\"\\nClassified action: {target_action}\")\n",
    "if target_action == \"LLM\":\n",
    "    print(\"\\n--- General Inquiry (Answering with LLM) ---\")\n",
    "    logger.info(\"Initiating LLM call for general inquiry.\")\n",
    "    # Call the asynchronous LLM function and wait for its result\n",
    "    try:\n",
    "        llm_response = asyncio.run(call_llm(user_query))\n",
    "        print(\"\\nLLM Response:\")\n",
    "        print(llm_response)\n",
    "        logger.info(\"LLM inquiry completed.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during LLM inquiry execution: {e}\")\n",
    "        print(f\"Failed to get LLM response: {e}\")\n",
    "\n",
    "elif target_action in [FRAUD_DETECTION_NOTEBOOK_PATH, CREDIT_RISK_NOTEBOOK_PATH, CUSTOMER_SEGMENTATION_NOTEBOOK_PATH]:\n",
    "    print(f\"\\n--- Routing to Notebook: {target_action} ---\")\n",
    "    print(\"Executing the target notebook. Its output will appear below.\")\n",
    "    print(\"-\" * 50) # Separator for clarity\n",
    "    logger.info(f\"Attempting to execute notebook: {target_action}\")\n",
    "\n",
    "    try:\n",
    "        # Using %run magic command to execute the notebook directly in this session.\n",
    "        %run $target_action\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"\\nSuccessfully executed notebook: {target_action}\")\n",
    "        logger.info(f\"Notebook '{target_action}' execution completed successfully.\")\n",
    "        print(\"Please review the output above for the model results.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error executing notebook '{target_action}': {e}\", exc_info=True) # exc_info to log traceback\n",
    "        print(f\"\\nError executing notebook '{target_action}': {e}\")\n",
    "        print(\"Please ensure the notebook path is correct and the notebook runs without errors.\")\n",
    "else:\n",
    "    print(\"\\n--- Unknown Classification ---\")\n",
    "    logger.warning(f\"Query '{user_query}' could not be classified to a known model.\")\n",
    "    print(\"Could not classify the query to a known model. Please rephrase or try a general inquiry.\")\n",
    "\n",
    "logger.info(\"--- Databricks RAG Model Router Execution Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "retrievalAugmentedGenerationModel",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
